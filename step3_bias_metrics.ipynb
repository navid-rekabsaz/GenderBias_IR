{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = ['BM25',\n",
    "               'BERT_Base',\n",
    "               ]\n",
    "\n",
    "metrics = ['RaB', 'ARaB'] \n",
    "methods = ['tf', 'bool']\n",
    "\n",
    "\n",
    "qry_bias_paths = {}\n",
    "for metric in metrics:\n",
    "    qry_bias_paths[metric] = {}\n",
    "    for exp_name in experiments:\n",
    "        qry_bias_paths[metric][exp_name] = {}\n",
    "        for _method in methods:\n",
    "            qry_bias_paths[metric][exp_name][_method] = 'data/msmarco_passage/run_bias_%s_%s_%s.pkl' % (exp_name, _method, metric)\n",
    "        \n",
    "\n",
    "queries_gender_annotated_path = \"resources/queries_gender_annotated.csv\"\n",
    "\n",
    "at_ranklist = [5, 10, 20, 30, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/msmarco_passage/run_bias_BM25_tf_RaB.pkl\n",
      "data/msmarco_passage/run_bias_BM25_bool_RaB.pkl\n",
      "data/msmarco_passage/run_bias_BERT_Base_tf_RaB.pkl\n",
      "data/msmarco_passage/run_bias_BERT_Base_bool_RaB.pkl\n",
      "data/msmarco_passage/run_bias_BM25_tf_ARaB.pkl\n",
      "data/msmarco_passage/run_bias_BM25_bool_ARaB.pkl\n",
      "data/msmarco_passage/run_bias_BERT_Base_tf_ARaB.pkl\n",
      "data/msmarco_passage/run_bias_BERT_Base_bool_ARaB.pkl\n"
     ]
    }
   ],
   "source": [
    "qry_bias_perqry = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    qry_bias_perqry[metric] = {}\n",
    "    for exp_name in experiments:\n",
    "        qry_bias_perqry[metric][exp_name] = {}\n",
    "        for _method in methods:\n",
    "            _path = qry_bias_paths[metric][exp_name][_method]\n",
    "            print (_path)\n",
    "            with open(_path, 'rb') as fr:\n",
    "                qry_bias_perqry[metric][exp_name][_method] = pickle.load(fr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1765"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_effective = {}\n",
    "with open(queries_gender_annotated_path, 'r') as fr:\n",
    "    for line in fr:\n",
    "        vals = line.strip().split(',')\n",
    "        qryid = int(vals[0])\n",
    "        qrytext = ' '.join(vals[1:-1])\n",
    "        qrygender = vals[-1]\n",
    "        if qrygender == 'n':\n",
    "            queries_effective[qryid] = qrytext\n",
    "len(queries_effective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_bias = {}\n",
    "eval_results_feml = {}\n",
    "eval_results_male = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    eval_results_bias[metric] = {}\n",
    "    eval_results_feml[metric] = {}\n",
    "    eval_results_male[metric] = {}\n",
    "    for exp_name in experiments:\n",
    "        eval_results_bias[metric][exp_name] = {}\n",
    "        eval_results_feml[metric][exp_name] = {}\n",
    "        eval_results_male[metric][exp_name] = {}\n",
    "        for _method in methods:\n",
    "            eval_results_bias[metric][exp_name][_method] = {}\n",
    "            eval_results_feml[metric][exp_name][_method] = {}\n",
    "            eval_results_male[metric][exp_name][_method] = {}\n",
    "            for at_rank in at_ranklist:\n",
    "                _bias_list = []\n",
    "                _feml_list = []\n",
    "                _male_list = []\n",
    "\n",
    "                for qryid in queries_effective.keys():\n",
    "                    if qryid in qry_bias_perqry[metric][exp_name][_method][at_rank]:\n",
    "                        _bias_list.append(qry_bias_perqry[metric][exp_name][_method][at_rank][qryid][0])\n",
    "                        _feml_list.append(qry_bias_perqry[metric][exp_name][_method][at_rank][qryid][1])\n",
    "                        _male_list.append(qry_bias_perqry[metric][exp_name][_method][at_rank][qryid][2])\n",
    "                    else:\n",
    "                        pass\n",
    "                        #print ('missing', metric, exp_name, _method, at_rank, qryid)\n",
    "\n",
    "                eval_results_bias[metric][exp_name][_method][at_rank] = np.mean([(_male_x-_feml_x) for _male_x, _feml_x in zip(_male_list, _feml_list)])\n",
    "                eval_results_feml[metric][exp_name][_method][at_rank] = np.mean(_feml_list)\n",
    "                eval_results_male[metric][exp_name][_method][at_rank] = np.mean(_male_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RaB\n",
      "                     BM25\t 5    tf\t-0.021162\t0.251156\t0.229994\n",
      "                BERT_Base\t 5    tf\t0.009629\t0.167259\t0.176888\n",
      "                     BM25\t 5  bool\t-0.017674\t0.205581\t0.187907\n",
      "                BERT_Base\t 5  bool\t0.010233\t0.153488\t0.163721\n",
      "==========\n",
      "                     BM25\t10    tf\t-0.004641\t0.219806\t0.215165\n",
      "                BERT_Base\t10    tf\t0.009101\t0.165929\t0.175030\n",
      "                     BM25\t10  bool\t0.000930\t0.182791\t0.183721\n",
      "                BERT_Base\t10  bool\t0.006202\t0.156279\t0.162481\n",
      "==========\n",
      "                     BM25\t20    tf\t-0.000462\t0.188988\t0.188526\n",
      "                BERT_Base\t20    tf\t0.015368\t0.148183\t0.163551\n",
      "                     BM25\t20  bool\t0.004419\t0.161628\t0.166047\n",
      "                BERT_Base\t20  bool\t0.013125\t0.139383\t0.152507\n",
      "==========\n",
      "                     BM25\t30    tf\t0.002845\t0.172844\t0.175689\n",
      "                BERT_Base\t30    tf\t0.013676\t0.144351\t0.158027\n",
      "                     BM25\t30  bool\t0.006512\t0.150388\t0.156899\n",
      "                BERT_Base\t30  bool\t0.013357\t0.133569\t0.146926\n",
      "==========\n",
      "                     BM25\t40    tf\t0.004768\t0.160903\t0.165672\n",
      "                BERT_Base\t40    tf\t0.016453\t0.141964\t0.158417\n",
      "                     BM25\t40  bool\t0.008256\t0.140581\t0.148837\n",
      "                BERT_Base\t40  bool\t0.015450\t0.131941\t0.147391\n",
      "==========\n",
      "ARaB\n",
      "                     BM25\t 5    tf\t-0.042829\t0.282248\t0.239419\n",
      "                BERT_Base\t 5    tf\t0.006539\t0.174030\t0.180569\n",
      "                     BM25\t 5  bool\t-0.035783\t0.223752\t0.187969\n",
      "                BERT_Base\t 5  bool\t0.006233\t0.155504\t0.161736\n",
      "==========\n",
      "                     BM25\t10    tf\t-0.024890\t0.256006\t0.231116\n",
      "                BERT_Base\t10    tf\t0.008214\t0.170777\t0.178992\n",
      "                     BM25\t10  bool\t-0.020275\t0.207754\t0.187478\n",
      "                BERT_Base\t10  bool\t0.007400\t0.155354\t0.162753\n",
      "==========\n",
      "                     BM25\t20    tf\t-0.012516\t0.227283\t0.214767\n",
      "                BERT_Base\t20    tf\t0.010885\t0.163642\t0.174527\n",
      "                     BM25\t20  bool\t-0.008038\t0.187941\t0.179903\n",
      "                BERT_Base\t20  bool\t0.009013\t0.151159\t0.160172\n",
      "==========\n",
      "                     BM25\t30    tf\t-0.008726\t0.211872\t0.203146\n",
      "                BERT_Base\t30    tf\t0.012359\t0.158190\t0.170549\n",
      "                     BM25\t30  bool\t-0.004022\t0.177325\t0.173303\n",
      "                BERT_Base\t30  bool\t0.010594\t0.146389\t0.156984\n",
      "==========\n",
      "                     BM25\t40    tf\t-0.005570\t0.200414\t0.194844\n",
      "                BERT_Base\t40    tf\t0.013913\t0.154461\t0.168374\n",
      "                     BM25\t40  bool\t-0.001048\t0.169089\t0.168041\n",
      "                BERT_Base\t40  bool\t0.012180\t0.143038\t0.155218\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for metric in metrics:\n",
    "    print (metric)\n",
    "    for at_rank in at_ranklist:\n",
    "        for _method in methods:\n",
    "            for exp_name in experiments:\n",
    "                print (\"%25s\\t%2d %5s\\t%f\\t%f\\t%f\" % (exp_name, at_rank, _method, eval_results_bias[metric][exp_name][_method][at_rank], eval_results_feml[metric][exp_name][_method][at_rank], eval_results_male[metric][exp_name][_method][at_rank]))\n",
    "        print (\"==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
